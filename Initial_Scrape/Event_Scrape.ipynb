{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "from html import unescape\n",
    "from datetime import datetime as dt\n",
    "import time\n",
    "import lxml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Web Scrape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup URL Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'http://ufcstats.com/statistics/events/completed'\n",
    "page = requests.get(url)\n",
    "soup = BeautifulSoup(page.text, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#List of more urls to scrape:\n",
    "detail_urls = [] #this grabs urls for each day recorded\n",
    "for url in soup.find_all(class_='b-link b-link_style_black'):\n",
    "    detail_urls.append(url['href'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'http://ufcstats.com/event-details/53278852bcd91e11'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "detail_urls[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set up datatype dictionary: \n",
    "\n",
    "data_types = {\n",
    "    'R_STR': int, \n",
    "    'B_STR': int,\n",
    "    'R_TD': int, \n",
    "    'B_TD': int, \n",
    "    'R_SUB': int, \n",
    "    'R_SUB': int, \n",
    "    'R_PASS': int, \n",
    "    'B_PASS': int,\n",
    "    'ROUND': int,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An image of a belt indicates a \"title match.\" find_belt determines if associated match is a title match:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_space_lines(text):\n",
    "    pattern1 = re.compile(r'[\\s\\s+]')\n",
    "    return re.sub(pattern1, ' ', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Determine if observation is a title-bout\n",
    "def find_belt(img_tag):\n",
    "    try:\n",
    "        image_link = img_tag['src']\n",
    "        if re.match(r'.*belt.*', image_link) != None:\n",
    "            return True\n",
    "    except:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_fight_auxiliary(soup):\n",
    "    '''\n",
    "    Input: beautifulsoup of an event url: (ie. http://www.ufcstats.com/event-details/53278852bcd91e11)\n",
    "    Outputs: pandas Series\n",
    "        date, location, attendance\n",
    "    '''\n",
    "    \n",
    "    table = []\n",
    "    \n",
    "    auxiliary_table = soup.find_all('li', {'class': 'b-list__box-list-item'})\n",
    "    for item in auxiliary_table:\n",
    "        attribute = remove_space_lines(item.text).strip()\n",
    "\n",
    "        #If attribute is missing, replace with ''\n",
    "        try:\n",
    "            attribute = re.findall(r'\\s\\s+(.*)', attribute)[0]\n",
    "        except:\n",
    "            attribute = '' \n",
    "        \n",
    "        table.append(attribute)\n",
    "        \n",
    "    table_series = pd.Series(table)\n",
    "    table_series.index = ['date', 'location', 'attendance']\n",
    "    \n",
    "    if table_series['attendance'] != '':\n",
    "        table_series['attendance'] = re.sub(',', '', table_series['attendance'])\n",
    "        table_series['attendance'] = int(table_series['attendance'])\n",
    "    \n",
    "    table_series['date'] = dt.strptime(table_series['date'], '%B %d, %Y').strftime('%d-%m-%Y')\n",
    "\n",
    "    return table_series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main Scraping Function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_page_stats(url):\n",
    "    \n",
    "    #Given url of list of events, returns list of event details:\n",
    "    #ie. return summary statistics for all fights on page like: http://www.ufcstats.com/event-details/53278852bcd91e11\n",
    "    \n",
    "    page = requests.get(url)\n",
    "    soup = BeautifulSoup(page.text, 'html.parser')\n",
    "    \n",
    "    stat_table = soup.findAll('table')[0].contents #Contents of the main table in html\n",
    "    \n",
    "    table_data = stat_table[3] #first 2 indices are empty strings, table_data is html starting from first table row\n",
    "    detail_data = table_data.find_all('p') #within table rows, there are <p> labels for table text\n",
    "    auxiliary_data = get_fight_auxiliary(soup) #Returns date, location, attendance of event\n",
    "    \n",
    "    image_data = table_data.find_all('img') #get image links to find belt for \n",
    "    \n",
    "    contents = [] #table contents\n",
    "    title_match_index = [] #used later to track which fights are title_bouts\n",
    "    \n",
    "    #Loop through elements of detail_data (html table) to scrape fight details:\n",
    "    for index, item in enumerate(detail_data):\n",
    "        \n",
    "        #find image of belt == title_bout\n",
    "        image = item.find('img')\n",
    "        if find_belt(image):\n",
    "            title_match_index.append(index) #grab index of fight in which belt appears\n",
    "            \n",
    "        #contents is list of all text from each element of table     \n",
    "        contents.append(item.text)  \n",
    "\n",
    "    \n",
    "    #Clean up elements\n",
    "    contents = list(map(lambda x: remove_space_lines(x), contents))\n",
    "    contents = list(map(lambda x: x.strip(), contents)) \n",
    "    \n",
    "    draw_index = []\n",
    "    \n",
    "    #When there's a draw or NC, additional tags are created --> remove the tag to reformat correctly   \n",
    "    for i in np.arange(0, len(contents)-10, 16):\n",
    "\n",
    "        if contents[i] != 'win':\n",
    "            \n",
    "            #Get the index of the match that was drawn & remove that element\n",
    "            draw_index.append(np.floor_divide(i, 16)) \n",
    "            contents.pop(i)\n",
    "                    \n",
    "    #Extract links to more detailed fight statistics\n",
    "    fight_links = table_data.find_all('a', {'class': 'b-flag b-flag_style_green'})\n",
    "    fight_links = [item['href'] for item in fight_links]\n",
    "    \n",
    "    draw_links = table_data.find_all('a', {'class': 'b-flag b-flag_style_bordered'})\n",
    "    draw_links = [item['href'] for item in draw_links]\n",
    "    draw_links = list(dict.fromkeys(draw_links)) #Remove duplicate links from the drawn fights\n",
    "    \n",
    "    for index, link in zip(draw_index, draw_links):\n",
    "        fight_links.insert(index, link)\n",
    "    \n",
    "    #each row of data is 16 elements: reformats 1 observation per row\n",
    "    formatted_contents = np.array(contents).reshape((-1, 16))\n",
    "    formatted_contents = pd.DataFrame(formatted_contents)\n",
    "    \n",
    "    #the first row is a list of 'wins'\n",
    "    #formatted_contents.drop(0, axis = 1, inplace = True)\n",
    "    \n",
    "    #Run a floor_divide to put the image of the belt in the correct fight\n",
    "\n",
    "    title_match = np.floor_divide(title_match_index, 16) \n",
    "\n",
    "    #Initialize title_bout column with all 0's\n",
    "    titles = np.zeros(16)\n",
    "    if len(title_match) != 0:\n",
    "        titles[title_match] = 1\n",
    "    \n",
    "    title_series = pd.Series(titles)\n",
    "    \n",
    "    formatted_contents['title_bout'] = title_series\n",
    "    \n",
    "    #rename columns\n",
    "    formatted_contents.columns = ['Winner', 'R_fighter', 'B_fighter', 'R_STR', 'B_STR', \n",
    "                               'R_TD', 'B_TD', 'R_SUB', 'R_SUB', 'R_PASS', 'B_PASS',\n",
    "                              'WEIGHT_CLASS', 'METHOD', 'DETAIL', 'ROUND', 'TIME', 'title_bout']\n",
    "    \n",
    "    #convert columns to appropriate data types\n",
    "    formatted_contents.replace('--', 99999, inplace = True)\n",
    "    formatted_contents = formatted_contents.astype(data_types)\n",
    "    formatted_contents['TIME'] = formatted_contents['TIME'].apply(lambda x: dt.strptime(x, '%M:%S').time())\n",
    "    formatted_contents['link'] = fight_links\n",
    "    \n",
    "    return (formatted_contents, auxiliary_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start Data Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-357ee2fa254d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     23\u001b[0m     \u001b[0mpage_index\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m     \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     26\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[1;31m#all_event_urls\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#Loop through main event pages (ie. http://www.ufcstats.com/statistics/events/completed)\n",
    "#extract each events' url in all_events_url:\n",
    "\n",
    "base_url = 'http://ufcstats.com/statistics/events/completed'\n",
    "\n",
    "all_event_urls = []\n",
    "page_index = 1\n",
    "\n",
    "while(True):\n",
    "    \n",
    "    url = base_url + '?page={}'.format(page_index)\n",
    "    page = requests.get(url)\n",
    "    soup = BeautifulSoup(page.content, 'html.parser')\n",
    "    \n",
    "    links = soup.find_all(class_='b-link b-link_style_black')\n",
    "    \n",
    "    if len(links) == 0:\n",
    "        break\n",
    "    \n",
    "    for item in links:\n",
    "        all_event_urls.append(item['href'])\n",
    "    \n",
    "    page_index += 1\n",
    "    \n",
    "    time.sleep(1)\n",
    "        \n",
    "#all_event_urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "483\n",
      "488\n",
      "492\n",
      "493\n",
      "494\n",
      "499\n",
      "500\n",
      "501\n",
      "502\n",
      "504\n",
      "505\n",
      "506\n",
      "507\n",
      "508\n",
      "509\n"
     ]
    }
   ],
   "source": [
    "#Loop through all events and extract summary statistics:\n",
    "all_events = []\n",
    "\n",
    "for index, url in enumerate(all_event_urls):\n",
    "    try:\n",
    "        all_events.append(get_page_stats(url))\n",
    "    except:\n",
    "        all_events.append(index)\n",
    "        print(index)\n",
    "        \n",
    "    time.sleep(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Debug:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_index = [item for item in all_events if type(item) != tuple]\n",
    "error_urls = [all_event_urls[item] for item in error_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[483, 488, 492, 493, 494, 499, 500, 501, 502, 504, 505, 506, 507, 508, 509]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "error_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'http://ufcstats.com/event-details/32a3025d5db456ae'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "error_url = all_event_urls[error_index[2]]\n",
    "error_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "483 http://ufcstats.com/event-details/cedfdf8d423d500c\n",
      "488 http://ufcstats.com/event-details/1a1a4d7a29041d77\n",
      "492 http://ufcstats.com/event-details/32a3025d5db456ae\n",
      "493 http://ufcstats.com/event-details/4a01dc8376736ef5\n",
      "494 http://ufcstats.com/event-details/749685d24e2cac50\n",
      "499 http://ufcstats.com/event-details/96eff1a628adcc7f\n",
      "500 http://ufcstats.com/event-details/9b5b5a75523728f3\n",
      "501 http://ufcstats.com/event-details/6ceff86fae4f6b3b\n",
      "502 http://ufcstats.com/event-details/aee8eecfc4bfb1e7\n",
      "504 http://ufcstats.com/event-details/b63e800c18e011b5\n",
      "505 http://ufcstats.com/event-details/31bbd46d57dfbcb7\n",
      "506 http://ufcstats.com/event-details/5af480a3b2e1726b\n",
      "507 http://ufcstats.com/event-details/1c3f5e85b59ec710\n",
      "508 http://ufcstats.com/event-details/dedc3bb440d09554\n",
      "509 http://ufcstats.com/event-details/b60391da771deefe\n"
     ]
    }
   ],
   "source": [
    "input_error_entries = []\n",
    "for index, url in zip(error_index, error_urls):\n",
    "    print(index, url)\n",
    "    input_error_entries.append(get_page_stats(url))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, data in zip(error_index, input_error_entries):\n",
    "    all_events[index] = data\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# To File:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index in np.arange(0, len(all_events)):\n",
    "    all_events[index][0]['date'] = all_events[index][1].loc['date']\n",
    "    all_events[index][0]['location'] = all_events[index][1].loc['location']\n",
    "    all_events[index][0]['attendance'] = all_events[index][1].loc['attendance']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "event_level_data = pd.DataFrame([])\n",
    "for item in all_events:\n",
    "    event_level_data = pd.concat([event_level_data, item[0]], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "event_level_data.reset_index(drop=True, inplace=True)\n",
    "event_level_data.to_csv('../Data/event_level_data.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
